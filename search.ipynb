{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The author is 'Aswani N'\n",
      "\n",
      "The titles of the author's publications are:\n",
      "Largescale Parallel Automatic Patent Annotation\n",
      "Largescale Parallel Automatic Patent Annotation\n",
      "Text Processing with GATE Version 6\n",
      "Text Processing with GATE Version 6\n",
      "MicroblogGenre Noise and Impact on Semantic Annotation Accuracy\n",
      "User Feedback Report on the EnviLOD Semantic Search Interface\n",
      "\n",
      "The top 25% most frequent words for this author are:\n",
      "'annotation',  'semantic',  'patent',  'text',  'processing',  'parallel',  'version',  '6', \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import jellyfish\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from Stemmer import Stemmer\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "stop_words = get_stop_words('en')\n",
    "p_stemmer = Stemmer('english')\n",
    "max_match = ['',0]\n",
    "all_text = []\n",
    "text = ''\n",
    "\n",
    "with open('all_titles.json', 'r+') as f:\n",
    "    all_titles = json.load(f)\n",
    "    f.close()\n",
    "with open('author_index.json', 'r+') as f:\n",
    "    author_index = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "input_val = raw_input('\\nEnter the name of the author to search: ')\n",
    "\n",
    "for key, value in author_index.items():\n",
    "    dist = jellyfish.jaro_distance(key.encode('utf-8'), input_val)\n",
    "    if dist > max_match[1]:\n",
    "        max_match[1] = dist\n",
    "        max_match[0] = key\n",
    "articles = author_index[max_match[0]]\n",
    "for i in articles:\n",
    "    all_text.append(all_titles[unicode(i)])\n",
    "for i in all_text:\n",
    "    text = text + \" \" + i\n",
    "text = re.sub('[^A-Za-z0-9 ]', ' ', text)\n",
    "chunk = nltk.word_tokenize(text.lower())\n",
    "tokens = [i for i in chunk if not i in stop_words]\n",
    "c = Counter(tokens)\n",
    "n = len(tokens)/4\n",
    "\n",
    "print \"\\nThe author is '{0}'\".format(max_match[0])\n",
    "print \"\\nThe titles of the author's publications are:\"\n",
    "for i in all_text:\n",
    "    print i\n",
    "print \"\\nThe top 25% most frequent words for this author are:\"\n",
    "for k in c.most_common(n):\n",
    "    print (\"'\" + k[0] + \"', \"), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
